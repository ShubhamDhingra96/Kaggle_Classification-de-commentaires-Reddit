{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nithi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import csv\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.text import Text\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "import itertools\n",
    "import operator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "train = np.load(\"./data/data_train.pkl\",allow_pickle=True)\n",
    "test=np.load(\"./data/data_test.pkl\",allow_pickle=True)\n",
    "X_train=train[0]\n",
    "y_train=train[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer()\n",
    "Tfidf_vect.fit(X_train)\n",
    "Train_X_Tfidf = Tfidf_vect.fit_transform(X_train)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C Bayes Accuracy Score ->  58.3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "C_navie = ComplementNB(alpha=2.5)\n",
    "C_navie.fit(Train_X_Tfidf,y_train)\n",
    "predictions_C_navie=C_navie.predict(Test_X_Tfidf)\n",
    "print(\"C Bayes Accuracy Score -> \",accuracy_score(predictions_C_navie, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lg=LogisticRegression(C=3 ,solver='sag',multi_class='multinomial',max_iter=500)\n",
    "lg.fit(Train_X_Tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5542857142857143\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = lg.predict(Test_X_Tfidf)\n",
    "print('accuracy %s' % accuracy_score(y_pred2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('CNB',\n",
       "                              ComplementNB(alpha=1.0, class_prior=None,\n",
       "                                           fit_prior=True, norm=False)),\n",
       "                             ('LSVC',\n",
       "                              LinearSVC(C=1, class_weight=None, dual=True,\n",
       "                                        fit_intercept=True, intercept_scaling=1,\n",
       "                                        loss='hinge', max_iter=4000,\n",
       "                                        multi_class='ovr', penalty='l2',\n",
       "                                        random_state=None, tol=0.0001,\n",
       "                                        verbose=0)),\n",
       "                             ('MNB',\n",
       "                              MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                            fit_prior=True))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = ComplementNB()\n",
    "clf2 = LinearSVC(loss='hinge', penalty='l2', C= 1, max_iter= 4000, multi_class= 'ovr' )\n",
    "clf3 = MultinomialNB()\n",
    "clf4=LogisticRegression(C=3 ,solver='sag',multi_class='multinomial',max_iter=500)\n",
    "\n",
    "eclf = VotingClassifier(estimators= [('CNB', clf1), ('LSVC', clf2), ('MNB', clf3)], voting= 'hard')\n",
    "eclf.fit(Train_X_Tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = eclf.predict(Test_X_Tfidf)\n",
    "\n",
    "#print('accuracy %s' % accuracy_score(new_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile=open(\"submission123.csv\",'w', newline='')\n",
    "obj=csv.writer(csvfile)\n",
    "obj.writerow((\"Id\",\"Category\"))\n",
    "for rowIndex,pred in enumerate(new_pred):\n",
    "    #test=Test.predict(test_sample)\n",
    "    #print(rowIndex)\n",
    "    #pred_class=Test.unique_class_Names[test]\n",
    "    obj.writerow((rowIndex,pred))\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
